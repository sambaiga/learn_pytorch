{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models:\n",
    "Models represent simplified or abstract descriptions of a process by which data are generated. Models in pyro are expressed as stochastic functions which implies that models can be composed, reused, imported, and serialized just like regular Python callables.\n",
    "\n",
    "## 1.2 Distributions\n",
    "\n",
    "An important class of models (stochastic functions) used explicitly to compute the probability of the outputs given the inputs.Distributions in pyro are implemented in [**pyro.distributions**](http://docs.pyro.ai/distributions.html) which is GPU-accelerated multivariate probability distributions. \n",
    "\n",
    "**Example 1**: Let define the unit normal distribution $\\mathcal{N}(0,1)$ and draw  sample $x$ and  compute the log probability according to the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some dependencies\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of normal distribution:  0.10484722256660461\n"
     ]
    }
   ],
   "source": [
    "mu = Variable(torch.zeros(1))   # mean zero\n",
    "sigma = Variable(torch.ones(1)) # unit variance\n",
    "x=dist.normal(mu, sigma) \n",
    "print(\"Sample of normal distribution: \", x.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability of 0.5654299259185791 is: -1.078794002532959 \n"
     ]
    }
   ],
   "source": [
    "#To compute the log probability according to the distribution\n",
    "log_p_x = dist.normal.log_pdf(x, mu, sigma)\n",
    "print(\"The log probability of {0} is: {1} \".format(x.data[0], log_p_x.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**: Let define the bernoulli distribution $\\mathcal{B}(0,1)$ and draw  sample $x$ and  compute the log probability according to the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of normal distribution:  1.0\n"
     ]
    }
   ],
   "source": [
    "prob = Variable(torch.Tensor([0.6]))\n",
    "x = dist.bernoulli(prob)\n",
    "print(\"Sample of normal distribution: \", x.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pyro Sample\n",
    "\n",
    "Sample  returns a named sample from the unit normal distribution. Pyro’s backend uses these names to uniquely identify sample statements and change their behavior at runtime depending on how the enclosing stochastic function is being used.\n",
    "\n",
    "**syntax: x = pyro.sample(\"my_sample\", fn, arg1, arg2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04278268665075302\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "x = pyro.sample(\"x_sample\", dist.normal, mu, sigma)\n",
    "print(x.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Simple model\n",
    "\n",
    "Suppose we have a bunch of data with power consumption of a TV with three states OFF, IDLE or ON. We want to reason about how power consumption of TV interacts with whether it was OFF, IDLE or ON. The probability of TV to be in ON state is 0.3 and that of OFF state is 0.7. A simple stochastic function (Model) that does that is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_model():\n",
    "    on_state = pyro.sample('ON', dist.bernoulli, Variable(torch.Tensor([0.3])))\n",
    "    on_state = 'ON' if on_state.data[0]==1.0 else 'OFF'\n",
    "    \n",
    "    mean_power = {'ON':[80], 'OFF': [0]}[on_state]\n",
    "    sigma_power = {'ON':[5], 'OFF': [10]}[on_state]\n",
    "    power = pyro.sample('power', dist.normal,Variable(torch.Tensor(mean_power)), Variable(torch.Tensor(sigma_power)))\n",
    "                                                      \n",
    "    return on_state, power.data[0]                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ON', 84.7545166015625)\n",
      "('ON', 77.65508270263672)\n",
      "('OFF', -5.8325934410095215)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(TV_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also build a billing model on top of the above defined model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_billing():\n",
    "    on_state, power = TV_model()\n",
    "    expected_cost = [30] if on_state == 'ON' and power > 80.0 else [5]\n",
    "    cost = pyro.sample('COST', dist.normal,\n",
    "                            Variable(torch.Tensor(expected_cost)),\n",
    "                            Variable(torch.Tensor([10.0])))\n",
    "    return on_state, cost.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('OFF', 1.3554277420043945)\n",
      "('OFF', -1.06915283203125)\n",
      "('OFF', -1.44720458984375)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(TV_billing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference: Marginal Distribution\n",
    "\n",
    "Suppose a model generate a joint probability distribution $p(y,z|x)$ over latent variable $z$ and return $y$. Then the question is how to compute the marginal probability of an output $p(y|x)$ or draw sample from marginal distribution.\n",
    "\n",
    "**Inference**  is the problem of constructing this marginal distribution given an arbitrary boolean constraint so that we can perform the above computations.\n",
    "\n",
    "To motivate the rest of this tutorial, let’s first build a generative model for a simple physical problem so that we can use Pyro’s inference machinery to solve it.\n",
    "\n",
    "In pyro the marginalization is implemented on **pyro.infer.Marginal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Suppose we are trying to figure out how much power an appliance cunsume, but the meter we’re using is unreliable and gives slightly different answers every time we monitor the same appliance. We could try to compensate for this variability by integrating the noisy measurement information with a guess based on some prior knowledge about the appliance, like its material properties. The following model encodes this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor(guess):\n",
    "    # The prior over weight encodes our uncertainty about our guess\n",
    "    power = pyro.sample(\"power\", dist.normal, guess, Variable(torch.ones(1)))\n",
    "    # This encodes our belief about the noisiness of the scale:\n",
    "    # the measurement fluctuates around the true power\n",
    "    return pyro.sample(\"measurement\", dist.normal, power, Variable(torch.Tensor([0.75])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Representing Marginal Distributions\n",
    "Before using our model to estimate  appliance power consumption let’s  analyzing our model’s behavior.Using importance sampling we can simulate the marginal distribution of measurement values we’d expect to see a priori for a given guess.\n",
    "\n",
    "To do this using marginalization we need to follow the follwing two steps\n",
    "- collect a number of weighted execution traces of the model.\n",
    "- collapse those traces into a histogram over possible return values given a particular set of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
